"""
Web AraÃ§larÄ± - Web search ve scraping
====================================
Bu modÃ¼lde ajanlarÄ±n kullanabileceÄŸi web tool'larÄ± var.

- Tavily API ile gerÃ§ek web search
- Mock data fallback
"""

import os
from typing import List, Dict
import time
from dotenv import load_dotenv

load_dotenv()


def search_web_simple(query: str, max_results: int = 5) -> List[Dict[str, str]]:
    """
    Web'de arama yapar (Tavily API)
    
    Args:
        query: Arama sorgusu
        max_results: DÃ¶ndÃ¼rÃ¼lecek maksimum sonuÃ§ sayÄ±sÄ±
        
    Returns:
        Arama sonuÃ§larÄ± listesi
        
    Her sonuÃ§ ÅŸu bilgileri iÃ§erir:
    - title: Sayfa baÅŸlÄ±ÄŸÄ±
    - url: Sayfa URL'i
    - snippet: KÄ±sa aÃ§Ä±klama
    """
    
    # Tip dÃ¶nÃ¼ÅŸÃ¼mÃ¼ (Gemini bazen string gÃ¶nderebilir)
    max_results = int(max_results)
    
    print(f"  ğŸ” Web'de aranÄ±yor: '{query}'")
    
    # Tavily API key kontrolÃ¼
    tavily_api_key = os.getenv('TAVILY_API_KEY')
    
    if tavily_api_key and tavily_api_key != 'your_tavily_api_key_here':
        # GerÃ§ek Tavily API kullan
        try:
            from tavily import TavilyClient
            
            client = TavilyClient(api_key=tavily_api_key)
            
            # Arama yap
            response = client.search(
                query=query,
                max_results=max_results,
                search_depth="basic"  # "basic" veya "advanced"
            )
            
            # SonuÃ§larÄ± formatla
            results = []
            for item in response.get('results', []):
                results.append({
                    'title': item.get('title', 'No title'),
                    'url': item.get('url', ''),
                    'snippet': item.get('content', '')[:200]  # Ä°lk 200 karakter
                })
            
            print(f"  âœ… {len(results)} sonuÃ§ bulundu (Tavily API)")
            return results
            
        except ImportError:
            print("  âš ï¸  Tavily kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil, mock data kullanÄ±lÄ±yor")
            return _mock_search_results(query, max_results)
        except Exception as e:
            print(f"  âš ï¸  Tavily API hatasÄ±: {e}, mock data kullanÄ±lÄ±yor")
            return _mock_search_results(query, max_results)
    else:
        # Mock data kullan
        print("  â„¹ï¸  Tavily API key bulunamadÄ±, mock data kullanÄ±lÄ±yor")
        return _mock_search_results(query, max_results)


def _mock_search_results(query: str, max_results: int) -> List[Dict[str, str]]:
    """Mock search results (Tavily API olmadÄ±ÄŸÄ±nda)"""
    time.sleep(0.5)  # GerÃ§ekÃ§i olsun diye
    
    mock_results = [
        {
            "title": f"Wikipedia - {query}",
            "url": f"https://en.wikipedia.org/wiki/{query.replace(' ', '_')}",
            "snippet": f"{query} hakkÄ±nda detaylÄ± Wikipedia makalesi. TanÄ±mlar, tarihÃ§e ve Ã¶rnekler iÃ§erir."
        },
        {
            "title": f"{query} Nedir? - KapsamlÄ± Rehber",
            "url": "https://example.com/rehber",
            "snippet": f"{query} konusunda baÅŸlangÄ±Ã§ seviyesinden ileri seviyeye kapsamlÄ± bilgiler."
        },
        {
            "title": f"Son GeliÅŸmeler: {query}",
            "url": "https://example.com/haberler",
            "snippet": f"{query} alanÄ±ndaki en son geliÅŸmeler ve trendler hakkÄ±nda gÃ¼ncel bilgiler."
        },
        {
            "title": f"{query} UygulamalarÄ±",
            "url": "https://example.com/uygulamalar",
            "snippet": f"GerÃ§ek dÃ¼nyada {query} nasÄ±l kullanÄ±lÄ±yor? Ã–rnekler ve vaka Ã§alÄ±ÅŸmalarÄ±."
        },
        {
            "title": f"{query} AraÅŸtÄ±rmalarÄ± ve Ä°statistikler",
            "url": "https://example.com/arastirma",
            "snippet": f"{query} hakkÄ±nda bilimsel araÅŸtÄ±rmalar, raporlar ve istatistiksel veriler."
        }
    ]
    
    results = mock_results[:max_results]
    print(f"  âœ… {len(results)} sonuÃ§ bulundu\n")
    
    return results

def fetch_url_content_simple(url: str) -> str:
    """
    Bir URL'in iÃ§eriÄŸini getirir (ÅŸimdilik mock data)
    
    Args:
        url: Ä°ndirilecek URL
        
    Returns:
        Sayfa iÃ§eriÄŸi (metin)
    """
    
    print(f"  ğŸŒ Sayfa indiriliyor: {url}")
    time.sleep(0.5)
    
    # Mock iÃ§erik - Crawl4AI ekleyince gerÃ§ek iÃ§erik gelecek
    mock_content = f"""
    Bu sayfa {url} adresinden mock (sahte) iÃ§eriktir.
    
    GerÃ§ek implementasyonda burada sayfanÄ±n tam iÃ§eriÄŸi olacak.
    Åimdilik ajanÄ±n tool'larÄ± nasÄ±l kullandÄ±ÄŸÄ±nÄ± gÃ¶rmek iÃ§in
    bu mock data'yÄ± kullanÄ±yoruz.
    
    Ä°leride:
    - Crawl4AI ile gerÃ§ek sayfalar taranacak
    - HTML temizlenip Markdown'a Ã§evrilecek
    - Sadece Ã¶nemli iÃ§erik gelecek
    """
    
    print(f"  âœ… Ä°Ã§erik indirildi ({len(mock_content)} karakter)\n")
    return mock_content.strip()

# Test fonksiyonu
if __name__ == "__main__":
    print("=" * 70)
    print("WEB TOOLS TEST")
    print("=" * 70)
    print()
    
    # Arama testi
    print("ğŸ“ Test 1: Web AramasÄ±")
    print("-" * 70)
    results = search_web_simple("yapay zeka", max_results=3)
    
    for i, result in enumerate(results, 1):
        print(f"{i}. {result['title']}")
        print(f"   URL: {result['url']}")
        print(f"   Ã–zet: {result['snippet'][:80]}...")
        print()
    
    # Ä°Ã§erik getirme testi
    print("ğŸ“ Test 2: URL Ä°Ã§erik Getirme")
    print("-" * 70)
    content = fetch_url_content_simple(results[0]['url'])
    print(content)
